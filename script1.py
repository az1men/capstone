# %% –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫
import RPi.GPIO as GPIO
from gpiozero import DistanceSensor
import cv2
import torch
import numpy as np
from torchvision import transforms
from torchvision.models import resnet50
from PIL import Image

print("Script is running...")

ultrasonic = DistanceSensor(echo=17, trigger=4)
LED_PIN = 16
GPIO.setmode(GPIO.BCM)
GPIO.setup(LED_PIN, GPIO.OUT)



# –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª–∏ –∏ –∫–ª–∞—Å—Å—ã
MODEL_PATH = "best_model.pth"
CLASSES = ["Black Scurf", "Blackleg", "Common Scab", "Dry Rot", "Healthy Potatoes", "Miscellaneous", "Pink Rot"]

# %% –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
model = resnet50()  # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É ResNet50
model.fc = torch.nn.Linear(in_features=2048, out_features=len(CLASSES))  # –ü–æ–¥—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥ —á–∏—Å–ª–æ –∫–ª–∞—Å—Å–æ–≤
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))  # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
model.to(DEVICE)
model.eval()

print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

# %% –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ç–æ –∂–µ —Å–∞–º–æ–µ, —á—Ç–æ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)
transform = transforms.Compose([
    transforms.Resize((224, 224)),  
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# %% –û—Ç–∫—Ä—ã—Ç–∏–µ –∫–∞–º–µ—Ä—ã
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É")
    exit()

while True:
    ret, frame = cap.read()

    if not ret:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä")
        break

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä—ã
    cv2.imshow('Camera', frame)

    key = cv2.waitKey(1) & 0xFF

    #if key == ord('c'):  # –ù–∞–∂–∞—Ç–∏–µ 'c' –¥–ª—è —Å–Ω–∏–º–∫–∞
    #    print("üì∏ –°–Ω–∏–º–æ–∫ —Å–¥–µ–ª–∞–Ω. –û–ø—Ä–µ–¥–µ–ª—è–µ–º...")

    distance_cm = ultrasonic.distance * 100
    if distance_cm < 40:  # If object is closer than 40 cm
        print("üì∏ Object detected! Taking a picture...")
        time.sleep(N) #wait N seconds for potato to reach camera

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # –ü–µ—Ä–µ–≤–æ–¥ –≤ RGB
        img = Image.fromarray(img)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ PIL
        img = transform(img).unsqueeze(0).to(DEVICE)  # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ–º batch size

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        with torch.no_grad():
            predictions = model(img)
            class_idx = torch.argmax(predictions, dim=1).item()
            probability = torch.nn.functional.softmax(predictions, dim=1)[0][class_idx].item()

        class_label = CLASSES[class_idx]  # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –∫–ª–∞—Å—Å–∞
        status = "Good" if class_label == "Healthy Potatoes" else "Bad"  # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å

        print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {class_label} ({status}) —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é {probability:.4f}")
        
        if status == "Bad":
            time.sleep(N) #wait N seconds for potato to reach linear actuator
            GPIO.output(LED_PIN, GPIO.HIGH)
            time.sleep(2)  # Keep LED on for 2 seconds
            GPIO.output(LED_PIN, GPIO.LOW) 
    

    elif key == ord('q'):  # –í—ã—Ö–æ–¥ –ø–æ 'q'
        break

# –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
GPIO.cleanup()
cap.release()
cv2.destroyAllWindows()